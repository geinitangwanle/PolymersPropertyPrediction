{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c481ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集形状: (7367, 110)\n",
      "前5行PSMILES:\n",
      "0                [*]#C[SiH2]C#Cc1cccc(C#[*])c1\n",
      "1       [*]#Cc1cccc(C#C[SiH](C#[*])c2ccccc2)c1\n",
      "2         [*]#Cc1ccccc1C#C[SiH](C#[*])c1ccccc1\n",
      "3    [*]/C(=C(/[*])c1ccc(C(C)(C)C)cc1)c1ccccc1\n",
      "4        [*]/C(=C(/[*])c1ccc(CCCC)cc1)c1ccccc1\n",
      "Name: PSMILES, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集中的规范化后的psmiles，使用polyBERT转换为嵌入向量\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取数据集\n",
    "data = pd.read_csv('LAMALAB_CURATED_Tg_structured.csv')\n",
    "print(f\"数据集形状: {data.shape}\")\n",
    "print(f\"前5行PSMILES:\")\n",
    "print(data['PSMILES'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2479fff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py38/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载 polyBERT 模型...\n",
      "模型加载完成!\n"
     ]
    }
   ],
   "source": [
    "# 加载 polyBERT 模型\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"正在加载 polyBERT 模型...\")\n",
    "polyBERT = SentenceTransformer('kuelumbus/polyBERT')\n",
    "print(\"模型加载完成!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9401e95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共有 7367 个 PSMILES\n",
      "空值数量: 0\n",
      "前5个PSMILES示例:\n",
      "1: [*]#C[SiH2]C#Cc1cccc(C#[*])c1\n",
      "2: [*]#Cc1cccc(C#C[SiH](C#[*])c2ccccc2)c1\n",
      "3: [*]#Cc1ccccc1C#C[SiH](C#[*])c1ccccc1\n",
      "4: [*]/C(=C(/[*])c1ccc(C(C)(C)C)cc1)c1ccccc1\n",
      "5: [*]/C(=C(/[*])c1ccc(CCCC)cc1)c1ccccc1\n"
     ]
    }
   ],
   "source": [
    "# 提取所有的 PSMILES\n",
    "psmiles_list = data['PSMILES'].tolist()\n",
    "print(f\"总共有 {len(psmiles_list)} 个 PSMILES\")\n",
    "\n",
    "# 检查是否有空值或无效数据\n",
    "print(f\"空值数量: {data['PSMILES'].isna().sum()}\")\n",
    "print(f\"前5个PSMILES示例:\")\n",
    "for i, psmiles in enumerate(psmiles_list[:5]):\n",
    "    print(f\"{i+1}: {psmiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595b1e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始对 PSMILES 进行编码转换...\n",
      "这可能需要几分钟时间，请耐心等待...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 231/231 [00:30<00:00,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码完成!\n",
      "嵌入向量形状: (7367, 600)\n",
      "每个 PSMILES 的嵌入向量维度: 600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用 polyBERT 对所有 PSMILES 进行编码转换为嵌入向量\n",
    "print(\"开始对 PSMILES 进行编码转换...\")\n",
    "print(\"这可能需要几分钟时间，请耐心等待...\")\n",
    "\n",
    "# 批量编码所有的 PSMILES\n",
    "psmiles_embeddings = polyBERT.encode(psmiles_list, show_progress_bar=True)\n",
    "\n",
    "print(f\"编码完成!\")\n",
    "print(f\"嵌入向量形状: {psmiles_embeddings.shape}\")\n",
    "print(f\"每个 PSMILES 的嵌入向量维度: {psmiles_embeddings.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118fbfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 嵌入向量存储完成 ===\n",
      "变量名: polymer_embeddings\n",
      "数据类型: <class 'numpy.ndarray'>\n",
      "形状: (7367, 600)\n",
      "数据类型: float32\n",
      "\n",
      "=== 嵌入向量统计信息 ===\n",
      "最小值: -3.132480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大值: 4.910603\n",
      "均值: -0.001582\n",
      "标准差: 0.624954\n",
      "\n",
      "=== 示例：前3个聚合物的嵌入向量（仅显示前10个维度）===\n",
      "PSMILES 1: [*]#C[SiH2]C#Cc1cccc(C#[*])c1\n",
      "嵌入向量前10维: [ 0.55221206  0.9560781   0.03296211 -0.34050205 -0.31080493  0.42567027\n",
      "  0.3735829  -0.25116748 -0.57380605  1.4445828 ]\n",
      "---\n",
      "PSMILES 2: [*]#Cc1cccc(C#C[SiH](C#[*])c2ccccc2)c1\n",
      "嵌入向量前10维: [ 0.4551718   0.6557985   0.31338024 -0.11561695 -0.5141235   0.17613572\n",
      "  0.14291468  0.21427798  0.12901457  0.6660925 ]\n",
      "---\n",
      "PSMILES 3: [*]#Cc1ccccc1C#C[SiH](C#[*])c1ccccc1\n",
      "嵌入向量前10维: [ 0.34316123  0.45972577  0.58509946  0.04770828 -0.59174454  0.02948072\n",
      " -0.03604525  0.00871426  0.36277086  0.32263896]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# 存储嵌入向量到变量中，并进行基本分析\n",
    "# 主要的嵌入向量矩阵\n",
    "polymer_embeddings = psmiles_embeddings\n",
    "\n",
    "print(\"=== 嵌入向量存储完成 ===\")\n",
    "print(f\"变量名: polymer_embeddings\")\n",
    "print(f\"数据类型: {type(polymer_embeddings)}\")\n",
    "print(f\"形状: {polymer_embeddings.shape}\")\n",
    "print(f\"数据类型: {polymer_embeddings.dtype}\")\n",
    "\n",
    "print(\"\\n=== 嵌入向量统计信息 ===\")\n",
    "print(f\"最小值: {polymer_embeddings.min():.6f}\")\n",
    "print(f\"最大值: {polymer_embeddings.max():.6f}\")\n",
    "print(f\"均值: {polymer_embeddings.mean():.6f}\")\n",
    "print(f\"标准差: {polymer_embeddings.std():.6f}\")\n",
    "\n",
    "print(\"\\n=== 示例：前3个聚合物的嵌入向量（仅显示前10个维度）===\")\n",
    "for i in range(3):\n",
    "    print(f\"PSMILES {i+1}: {psmiles_list[i]}\")\n",
    "    print(f\"嵌入向量前10维: {polymer_embeddings[i][:10]}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3293387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 嵌入向量归一化 ===\n",
      "原始嵌入向量统计:\n",
      "形状: (7367, 600)\n",
      "最小值: -3.132480\n",
      "最大值: 4.910603\n",
      "均值: -0.001582\n",
      "标准差: 0.624954\n",
      "L2归一化后的向量范数（前5个）: [0.99999994 1.         1.         0.99999994 1.        ]\n",
      "L2归一化后统计 - 最小值: -0.188396, 最大值: 0.305970\n",
      "L2归一化后统计 - 均值: -0.000104, 标准差: 0.040825\n",
      "\n",
      "主要归一化变量: normalized_embeddings (L2归一化)\n",
      "形状: (7367, 600)\n"
     ]
    }
   ],
   "source": [
    "# 对嵌入向量进行归一化\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "print(\"=== 嵌入向量归一化 ===\")\n",
    "print(\"原始嵌入向量统计:\")\n",
    "print(f\"形状: {polymer_embeddings.shape}\")\n",
    "print(f\"最小值: {polymer_embeddings.min():.6f}\")\n",
    "print(f\"最大值: {polymer_embeddings.max():.6f}\")\n",
    "print(f\"均值: {polymer_embeddings.mean():.6f}\")\n",
    "print(f\"标准差: {polymer_embeddings.std():.6f}\")\n",
    "# L2归一化：每个向量的L2范数归一化为1，保持余弦相似性\n",
    "polymer_embeddings_l2 = normalize(polymer_embeddings, norm='l2', axis=1)\n",
    "\n",
    "print(f\"L2归一化后的向量范数（前5个）: {np.linalg.norm(polymer_embeddings_l2[:5], axis=1)}\")\n",
    "print(f\"L2归一化后统计 - 最小值: {polymer_embeddings_l2.min():.6f}, 最大值: {polymer_embeddings_l2.max():.6f}\")\n",
    "print(f\"L2归一化后统计 - 均值: {polymer_embeddings_l2.mean():.6f}, 标准差: {polymer_embeddings_l2.std():.6f}\")\n",
    "\n",
    "# 为了方便后续使用，将L2归一化版本设为主要变量\n",
    "normalized_embeddings = polymer_embeddings_l2\n",
    "print(f\"\\n主要归一化变量: normalized_embeddings (L2归一化)\")\n",
    "print(f\"形状: {normalized_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce172cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1c841f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数量: 5893\n",
      "验证集数量: 737\n",
      "测试集数量: 737\n"
     ]
    }
   ],
   "source": [
    "# 按照 8:1:1 划分数据集\n",
    "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"训练集数量: {len(train_data)}\")\n",
    "print(f\"验证集数量: {len(val_data)}\")\n",
    "print(f\"测试集数量: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9c0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取对应的索引用于后续的嵌入向量划分\n",
    "train_indices = train_data.index.tolist()\n",
    "val_indices = val_data.index.tolist() if len(val_data) > 0 else []\n",
    "test_indices = test_data.index.tolist() if len(test_data) > 0 else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0b472ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 嵌入向量划分 ===\n",
      "训练集嵌入向量: (5893, 600)\n",
      "验证集嵌入向量: (737, 600)\n",
      "测试集嵌入向量: (737, 600)\n"
     ]
    }
   ],
   "source": [
    "# 如果已有嵌入向量，同时划分嵌入向量\n",
    "if 'normalized_embeddings' in globals():\n",
    "    train_embeddings = normalized_embeddings[train_indices]\n",
    "    val_embeddings = normalized_embeddings[val_indices] if len(val_indices) > 0 else np.array([])\n",
    "    test_embeddings = normalized_embeddings[test_indices] if len(test_indices) > 0 else np.array([])\n",
    "    \n",
    "    print(f\"\\n=== 嵌入向量划分 ===\")\n",
    "    print(f\"训练集嵌入向量: {train_embeddings.shape}\")\n",
    "    print(f\"验证集嵌入向量: {val_embeddings.shape}\")\n",
    "    print(f\"测试集嵌入向量: {test_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad21d4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 目标变量 Tg 值 ===\n",
      "训练集 Tg 范围: 134.15 - 763.15 K\n",
      "验证集 Tg 范围: 153.05 - 768.15 K\n",
      "测试集 Tg 范围: 144.15 - 677.15 K\n"
     ]
    }
   ],
   "source": [
    "# 提取目标变量 Tg 值\n",
    "train_y = train_data['Tg'].values\n",
    "val_y = val_data['Tg'].values if len(val_data) > 0 else np.array([])\n",
    "test_y = test_data['Tg'].values if len(test_data) > 0 else np.array([])\n",
    "\n",
    "print(f\"\\n=== 目标变量 Tg 值 ===\")\n",
    "print(f\"训练集 Tg 范围: {train_y.min():.2f} - {train_y.max():.2f} K\")\n",
    "if len(val_y) > 0:\n",
    "    print(f\"验证集 Tg 范围: {val_y.min():.2f} - {val_y.max():.2f} K\")\n",
    "if len(test_y) > 0:\n",
    "    print(f\"测试集 Tg 范围: {test_y.min():.2f} - {test_y.max():.2f} K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5fa8f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Tg预测机器学习模型训练 ===\n",
      "训练集: 5893 样本, 600 特征\n",
      "验证集: 737 样本\n",
      "测试集: 737 样本\n",
      "\n",
      "=== 开始训练 8 个模型 ===\n",
      "\n",
      "训练 Linear Regression...\n",
      "Linear Regression 训练完成 ✓\n",
      "\n",
      "训练 Ridge Regression...\n",
      "Ridge Regression 训练完成 ✓\n",
      "\n",
      "训练 ElasticNet...\n",
      "ElasticNet 训练完成 ✓\n",
      "\n",
      "训练 Random Forest...\n",
      "Random Forest 训练完成 ✓\n",
      "\n",
      "训练 Gradient Boosting...\n",
      "Gradient Boosting 训练完成 ✓\n",
      "\n",
      "训练 SVR...\n",
      "SVR 训练完成 ✓\n",
      "\n",
      "训练 Neural Network...\n",
      "Neural Network 训练完成 ✓\n",
      "\n",
      "训练 XGBoost...\n",
      "XGBoost 训练完成 ✓\n",
      "\n",
      "=== 模型性能评估结果 ===\n",
      "                      Model         MSE      RMSE      MAE      R²\n",
      "0   Linear Regression_train   1576.8364   39.7094  29.6730  0.8759\n",
      "1     Linear Regression_val   2018.5120   44.9279  33.4028  0.8461\n",
      "2    Linear Regression_test   2328.7365   48.2570  34.8917  0.8091\n",
      "3    Ridge Regression_train   2130.0215   46.1522  34.4824  0.8324\n",
      "4      Ridge Regression_val   2294.8087   47.9042  35.2852  0.8250\n",
      "5     Ridge Regression_test   2480.9304   49.8089  36.7014  0.7966\n",
      "6          ElasticNet_train  11370.6777  106.6334  89.4251  0.1051\n",
      "7            ElasticNet_val  11743.2512  108.3663  90.6003  0.1044\n",
      "8           ElasticNet_test  10908.8642  104.4455  87.9425  0.1058\n",
      "9       Random Forest_train    297.5553   17.2498  12.5011  0.9766\n",
      "10        Random Forest_val   2281.2368   47.7623  34.3359  0.8260\n",
      "11       Random Forest_test   2323.4898   48.2026  34.4026  0.8095\n",
      "12  Gradient Boosting_train   1700.7521   41.2402  31.6849  0.8661\n",
      "13    Gradient Boosting_val   2634.3167   51.3256  37.8928  0.7991\n",
      "14   Gradient Boosting_test   2617.6580   51.1631  38.2775  0.7854\n",
      "15                SVR_train   4507.0006   67.1342  52.1964  0.6453\n",
      "16                  SVR_val   4708.9239   68.6216  53.6869  0.6409\n",
      "17                 SVR_test   4418.7070   66.4734  51.9170  0.6378\n",
      "18     Neural Network_train    981.6433   31.3312  22.3260  0.9227\n",
      "19       Neural Network_val   1773.4034   42.1118  29.9513  0.8648\n",
      "20      Neural Network_test   1896.8064   43.5523  29.3474  0.8445\n",
      "21            XGBoost_train     44.1585    6.6452   5.0853  0.9965\n",
      "22              XGBoost_val   2181.8759   46.7106  33.4937  0.8336\n",
      "23             XGBoost_test   2105.8567   45.8896  32.5315  0.8274\n",
      "\n",
      "=== 最佳模型: Neural Network ===\n",
      "最佳性能: R² = 0.8648, RMSE = 42.1118\n"
     ]
    }
   ],
   "source": [
    "# 使用机器学习模型训练Tg预测\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子确保可重现性\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=== Tg预测机器学习模型训练 ===\")\n",
    "\n",
    "# 检查数据是否存在\n",
    "if not all([var in globals() for var in ['train_embeddings', 'val_embeddings', 'test_embeddings', 'train_y', 'val_y', 'test_y']]):\n",
    "    print(\"错误: 请先运行数据划分代码\")\n",
    "    exit()\n",
    "\n",
    "print(f\"训练集: {train_embeddings.shape[0]} 样本, {train_embeddings.shape[1]} 特征\")\n",
    "print(f\"验证集: {val_embeddings.shape[0]} 样本\" if len(val_embeddings) > 0 else \"验证集: 0 样本\")\n",
    "print(f\"测试集: {test_embeddings.shape[0]} 样本\" if len(test_embeddings) > 0 else \"测试集: 0 样本\")\n",
    "\n",
    "# 定义评估指标函数\n",
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"计算回归模型评估指标\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R²': r2\n",
    "    }\n",
    "\n",
    "# 定义模型字典\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0, random_state=42),\n",
    "    'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=2000),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR(kernel='rbf', C=1.0, gamma='scale'),\n",
    "    'Neural Network': MLPRegressor(hidden_layer_sizes=(256, 128, 64), \n",
    "                                   max_iter=500, \n",
    "                                   random_state=42, \n",
    "                                   early_stopping=True,\n",
    "                                   validation_fraction=0.1),\n",
    "}\n",
    "\n",
    "# 如果有xgboost，添加XGBoost模型\n",
    "try:\n",
    "    models['XGBoost'] = xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "except:\n",
    "    print(\"XGBoost不可用，跳过XGBoost模型\")\n",
    "\n",
    "print(f\"\\n=== 开始训练 {len(models)} 个模型 ===\")\n",
    "\n",
    "# 存储结果\n",
    "results = []\n",
    "trained_models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 训练和评估每个模型\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n训练 {model_name}...\")\n",
    "    \n",
    "    try:\n",
    "        # 训练模型\n",
    "        model.fit(train_embeddings, train_y)\n",
    "        trained_models[model_name] = model\n",
    "        \n",
    "        # 预测\n",
    "        train_pred = model.predict(train_embeddings)\n",
    "        predictions[f'{model_name}_train'] = train_pred\n",
    "        \n",
    "        # 评估训练集\n",
    "        train_metrics = evaluate_model(train_y, train_pred, f\"{model_name}_train\")\n",
    "        results.append(train_metrics)\n",
    "        \n",
    "        # 如果有验证集，在验证集上评估\n",
    "        if len(val_embeddings) > 0:\n",
    "            val_pred = model.predict(val_embeddings)\n",
    "            predictions[f'{model_name}_val'] = val_pred\n",
    "            val_metrics = evaluate_model(val_y, val_pred, f\"{model_name}_val\")\n",
    "            results.append(val_metrics)\n",
    "        \n",
    "        # 如果有测试集，在测试集上预测\n",
    "        if len(test_embeddings) > 0:\n",
    "            test_pred = model.predict(test_embeddings)\n",
    "            predictions[f'{model_name}_test'] = test_pred\n",
    "            test_metrics = evaluate_model(test_y, test_pred, f\"{model_name}_test\")\n",
    "            results.append(test_metrics)\n",
    "            \n",
    "        print(f\"{model_name} 训练完成 ✓\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{model_name} 训练失败: {e}\")\n",
    "        continue\n",
    "\n",
    "# 将结果转换为DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(f\"\\n=== 模型性能评估结果 ===\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# 找出最佳模型（基于验证集或训练集R²）\n",
    "if len(val_embeddings) > 0:\n",
    "    val_results = results_df[results_df['Model'].str.contains('_val')]\n",
    "    if len(val_results) > 0:\n",
    "        best_model_row = val_results.loc[val_results['R²'].idxmax()]\n",
    "        best_model_name = best_model_row['Model'].replace('_val', '')\n",
    "    else:\n",
    "        train_results = results_df[results_df['Model'].str.contains('_train')]\n",
    "        best_model_row = train_results.loc[train_results['R²'].idxmax()]\n",
    "        best_model_name = best_model_row['Model'].replace('_train', '')\n",
    "else:\n",
    "    train_results = results_df[results_df['Model'].str.contains('_train')]\n",
    "    best_model_row = train_results.loc[train_results['R²'].idxmax()]\n",
    "    best_model_name = best_model_row['Model'].replace('_train', '')\n",
    "\n",
    "print(f\"\\n=== 最佳模型: {best_model_name} ===\")\n",
    "print(f\"最佳性能: R² = {best_model_row['R²']:.4f}, RMSE = {best_model_row['RMSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b460b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
